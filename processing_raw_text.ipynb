{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, re, pprint\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Accessing Text from the Web and from Disk\n",
    "\n",
    "**Electronic Books:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(str,\n",
       " 1176811,\n",
       " 'The Project Gutenberg eBook of Crime and Punishment, by Fyodor Dostoevsky\\r\\n')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib import request\n",
    "url = \"http://www.gutenberg.org/files/2554/2554-0.txt\"\n",
    "response = request.urlopen(url)\n",
    "raw = response.read().decode('utf-8-sig')\n",
    "type(raw), len(raw), raw[:75]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tokenization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Project', 'Gutenberg', 'eBook', 'of', 'Crime', 'and', 'Punishment', ',', 'by']\n"
     ]
    }
   ],
   "source": [
    "tokens = word_tokenize(raw)\n",
    "type(tokens), len(tokens)\n",
    "print(tokens[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['insight', 'impresses', 'us', 'as', 'wisdom', '...', 'that', 'wisdom', 'of', 'the', 'heart', 'which', 'we', 'seek', 'that', 'we', 'may', 'learn', 'from', 'it', 'how', 'to', 'live', '.', 'All', 'his', 'other', 'gifts', 'came', 'to', 'him', 'from', 'nature', ',', 'this', 'he', 'won', 'for']\n",
      "Katerina Ivanovna; Pyotr Petrovitch; Pulcheria Alexandrovna; Avdotya\n",
      "Romanovna; Rodion Romanovitch; Marfa Petrovna; Sofya Semyonovna; old\n",
      "woman; Project Gutenberg-tm; Porfiry Petrovitch; Amalia Ivanovna;\n",
      "great deal; young man; Nikodim Fomitch; Project Gutenberg; Ilya\n",
      "Petrovitch; Andrey Semyonovitch; Hay Market; Dmitri Prokofitch; Good\n",
      "heavens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(nltk.text.Text, None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = nltk.Text(tokens)\n",
    "print(text[1024:1062])\n",
    "type(text), text.collocations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remove artifacts from text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5574"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.find('PART I') # Case sensitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1158052"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.rfind(\"END OF THE PROJECT GUTENBERG EBOOK CRIME AND PUNISHMENT\") # reverse find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = raw[5574:1158052]\n",
    "raw.find(\"PART I\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with HTML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!doctype html public \"-//W3C//DTD HTML 4.0 Transitional//EN'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"http://news.bbc.co.uk/2/hi/health/2284783.stm\"\n",
    "html = request.urlopen(url).read().decode('utf-8')\n",
    "html[:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BBC', 'NEWS', '|', 'Health', '|', 'Blondes', \"'to\", 'die', 'out', 'in', '200', \"years'\", 'CATEGORIES', 'TV', 'RADIO', 'COMMUNICATE', 'WHERE', 'I', 'LIVE', 'INDEX']\n",
      "['Blondes', \"'to\", 'die', 'out', 'in', '200', \"years'\", 'Scientists', 'believe', 'the', 'last', 'blondes', 'will', 'be', 'in', 'Finland', 'The', 'last', 'natural', 'blondes']\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "raw = BeautifulSoup(html, 'html.parser').get_text()\n",
    "tokens = word_tokenize(raw)\n",
    "print(tokens[:20])\n",
    "\n",
    "tokens = tokens[112:392]\n",
    "print(tokens[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 5 of 5 matches:\n",
      "hey say too few people now carry the gene for blondes to last beyond the next \n",
      "blonde hair is caused by a recessive gene . In order for a child to have blond\n",
      " have blonde hair , it must have the gene on both sides of the family in the g\n",
      "ere is a disadvantage of having that gene or by chance . They do n't disappear\n",
      "des would disappear is if having the gene was a disadvantage and I do not thin\n"
     ]
    }
   ],
   "source": [
    "text = nltk.Text(tokens)\n",
    "text.concordance('gene')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing RSS feeds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import feedparser\n",
    "llog = feedparser.parse(\"http://languagelog.ldc.upenn.edu/nll/?feed=atom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Language Log', 13)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llog['feed']['title'], len(llog.entries) # blog title and number of blog entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Shooketh, rattleth, and rolleth'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post = llog.entries[1]\n",
    "post.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<p>In his \"The Good Word\" column of The Atlantic (1/24/22), Caleb Madison has a new article, \"Why We’re All Shooketh:\\xa0 The term is online slang of Biblical proportions\".\\xa0 The first two paragraphs:</p>\\n<p style=\"padding-left: 40px;\">Lately modern life has felt all too biblical. Plagues, <a href=\"https://www.theatlantic.com/science/archive/2021/09/summer-climate-disaster/620004/\">massive weather events</a>, <a href=\"https://www.theatlantic.com/magazine/archive/2021/07/george-packer-four-americas/619012/\">tribal divisions</a>, demagogic leadership … and people using words like <em>shooketh</em>. The phrase <em>I’m shooketh</em> was first uttered by the comedian Christine Sydelko in a <a href=\"h'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content = post.content[0].value\n",
    "content[:700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In', 'his', '``', 'The', 'Good', 'Word', \"''\", 'column', 'of', 'The', 'Atlantic', '(', '1/24/22', ')', ',', 'Caleb', 'Madison', 'has', 'a', 'new', 'article', ',', '``', 'Why', 'We', '’', 're', 'All', 'Shooketh', ':', 'The', 'term', 'is', 'online', 'slang', 'of', 'Biblical', 'proportions', \"''\", '.', 'The', 'first', 'two', 'paragraphs', ':', 'Lately', 'modern', 'life', 'has', 'felt', 'all', 'too', 'biblical', '.', 'Plagues', ',', 'massive', 'weather', 'events', ',', 'tribal', 'divisions', ',', 'demagogic', 'leadership', '…', 'and', 'people', 'using', 'words', 'like', 'shooketh', '.', 'The', 'phrase', 'I', '’', 'm', 'shooketh', 'was', 'first', 'uttered', 'by', 'the', 'comedian', 'Christine', 'Sydelko', 'in', 'a', 'YouTube', 'video', 'uploaded', 'to', 'her', 'account', 'in', '2017', '(', 'she', 'was', 'expressing', 'her', 'shock', 'at', 'having', 'been', 'recognized', 'by', 'a', 'fan', 'at', 'Boston', 'Market', ')', '.', 'The', 'adjective', 'shooketh', 'took', 'off', 'as', 'a', 'way', 'to', 'lend', 'biblical', 'proportions', 'to', 'awestruck', 'confusion', '.', 'But', 'the', 'linguistic', 'journey', 'to', 'its', 'creation', 'spans', 'the', 'evolution', 'of', 'the', 'English', 'language', ',', 'connecting', 'Early', 'Modern', 'English', ',', 'turn-of-the-century', 'adventure', 'novels', ',', 'and', 'Twitter', 'slang', '.', 'When', 'we', 'want', 'to', 'transform', 'verbs', 'like', 'shake', 'into', 'adjectives', ',', 'we', 'typically', 'use', 'something', 'called', 'a', 'participle', ',', 'either', 'present', 'or', 'past', '.', 'The', 'present', 'participle', 'of', 'shake', 'is', 'shaking', ',', 'as', 'in', '“', 'I', '’', 'm', 'shaking.', '”', 'The', 'past', 'participle', 'would', 'be', '“', 'I', '’', 'm', 'shaken.', '”', 'But', ',', 'for', 'some', 'reason', ',', 'in', 'the', '19th', 'century', ',', 'the', 'simple', 'past', 'tense', ',', 'shook', ',', 'took', 'hold', '.', 'In', 'Robert', 'Louis', 'Stevenson', '’', 's', '1883', 'adventure', 'classic', 'Treasure', 'Island', ',', 'Long', 'John', 'Silver', 'admits', ',', '“', 'I', '’', 'll', 'not', 'deny', 'neither', 'but', 'what', 'some', 'of', 'my', 'people', 'was', 'shook—maybe', 'all', 'was', 'shook', ';', 'maybe', 'I', 'was', 'shook', 'myself.', '”', 'And', '14', 'years', 'later', ',', 'in', 'Rudyard', 'Kipling', '’', 's', 'Captains', 'Courageous', ',', 'the', 'form', 'reappears', 'within', 'a', 'now-common', 'collocation', 'with', 'up', 'when', 'Dan', 'Troop', 'exclaims', ',', '“', 'Well', ',', 'you', 'was', 'shook', 'up', 'and', 'silly.', '”', 'Before', 'proceeding', 'on', 'to', 'account', 'for', 'the', '-eth', 'suffix', ',', 'I', 'want', 'to', 'call', 'attention', 'to', 'a', 'usage', 'in', 'the', 'quotations', 'from', 'Robert', 'Louis', 'Stevenson', 'and', 'Rudyard', 'Kipling', ',', 'namely', ',', '``', 'some', 'of', 'my', 'people', 'was', 'shook—maybe', 'all', 'was', 'shook', \"''\", 'and', '``', 'you', 'was', 'shook', 'up', \"''\", '.', 'Madison', 'does', \"n't\", 'comment', 'on', 'this', ',', 'but', 'it', 'documents', 'the', 'lack', 'of', 'grammatical', 'agreement', 'in', 'the', 'past', 'tense', 'of', 'the', 'verb', '``', 'be', \"''\", 'during', 'the', 'second', 'half', 'of', 'the', '19th', 'century', '.', 'It', \"'s\", 'not', 'that', 'I', 'find', 'that', 'particularly', 'surprising', ',', 'but', 'it', 'makes', 'me', 'wonder', 'how', 'far', 'such', 'verbal', 'disagreement', 'goes', 'back', 'before', 'the', 'second', 'half', 'of', 'the', '19th', 'century', '.', 'I', 'suspect', 'that', 'it', 'goes', 'back', 'a', 'very', 'long', 'time', ',', 'though', 'I', 'have', 'little', 'documentation', 'for', 'my', 'surmise', '(', 'see', '``', 'Selected', 'readings', \"''\", 'below', ')', '.', 'Now', 'to', 'the', 'second', 'half', 'of', 'the', 'combination', ':', 'the', 'suffix', '-eth', '.', 'To', 'make', 'shooketh', '’', 's', 'relationship', 'to', 'tense', 'even', 'more', '…', 'uh', '…', 'well', '…', 'tense', '…', '-eth', 'was', 'used', 'in', 'Early', 'Modern', 'English', '(', 'think', 'Shakespeare', 'and', 'the', 'King', 'James', 'Bible', ')', 'to', 'put', 'verbs', 'in', 'the', 'third-person', 'present', 'tense', '.', 'Back', 'then', ',', 'English', 'had', 'different', 'verb', 'endings', 'depending', 'on', 'who', 'was', 'doing', 'the', 'action', '.', '“', 'I', 'love', ',', '”', 'yes', ',', 'but', '“', 'thou', 'lovest', '”', 'and', '“', 'he/she/it', 'loveth.', '”', 'Soon', ',', '-eth', 'simplified', 'to', 'just', '-s', ',', 'but', 'we', 'still', 'use', 'the', 'form', 'when', 'we', 'need', 'to', 'give', 'our', 'verbs', 'a', 'little', 'extra', 'ancient', 'oomph', '.', 'It', 'just', 'wouldn', '’', 't', 'be', 'as', 'momentous', 'to', 'say', '“', 'The', 'Lord', 'gives', 'and', 'the', 'Lord', 'takes', 'away', '!', '”', 'And', 'it', 'certainly', 'wouldn', '’', 't', 'be', 'as', 'cool', 'to', 'say', '“', 'I', '’', 'm', 'shooks.', '”', 'But', 'our', 'distance', 'from', 'the', 'Elizabethan', 'era', 'allows', '-eth', 'to', 'reappear', 'with', 'no', 'tense', 'tension', '.', 'Instead', ',', 'it', 'simply', 'adds', 'a', 'wry', 'dramatic', 'flourish', 'to', 'the', 'feeling', 'of', 'being', 'shook', '.', 'If', 'using', 'shook', 'dials', 'the', 'shock', 'of', 'shaken', 'up', 'a', 'notch', ',', 'adding', '-eth', 'pushes', 'the', 'intensity', 'to', '11', ',', 'expressing', 'a', 'holy', 'and', 'almost', 'sublime', 'desire', 'in', 'the', 'face', 'of', 'inexplicable', 'events', '.', 'Shooketh', 'yokes', 'together', 'a', 'punchy', 'modern', 'verbal', 'innovation', 'with', 'a', 'dramatic', 'formal', 'relic', 'of', 'early', 'English', 'to', 'communicate', 'a', 'shaking', 'of', 'biblical', 'proportions', '.', 'Hence', 'the', 'Thursday-level', 'clue']\n"
     ]
    }
   ],
   "source": [
    "raw = BeautifulSoup(content, 'html.parser').get_text()\n",
    "print(word_tokenize(raw)[:700])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
