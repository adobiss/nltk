{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, re, pprint\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "corpus = nltk.corpus.nps_chat\n",
    "\n",
    "corpus.ensure_loaded()\n",
    "posts = corpus.xml_posts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Training to establish dialogue acts:\n",
    "\n",
    "d_acts = []\n",
    "\n",
    "for p in posts:\n",
    "    if p.get('class') not in d_acts:\n",
    "            d_acts.append(p.get('class'))\n",
    "sorted(d_acts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Preprocessing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"D:\\ML\\Datasets\\labeled_lyrics_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>artist</th>\n",
       "      <th>seq</th>\n",
       "      <th>song</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Elijah Blake</td>\n",
       "      <td>No, no\\r\\nI ain't ever trapped out the bando\\r...</td>\n",
       "      <td>Everyday</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Elijah Blake</td>\n",
       "      <td>The drinks go down and smoke goes up, I feel m...</td>\n",
       "      <td>Live Till We Die</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Elijah Blake</td>\n",
       "      <td>She don't live on planet Earth no more\\r\\nShe ...</td>\n",
       "      <td>The Otherside</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Elijah Blake</td>\n",
       "      <td>Trippin' off that Grigio, mobbin', lights low\\...</td>\n",
       "      <td>Pinot</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Elijah Blake</td>\n",
       "      <td>I see a midnight panther, so gallant and so br...</td>\n",
       "      <td>Shadows &amp; Diamonds</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        artist  \\\n",
       "0           0  Elijah Blake   \n",
       "1           1  Elijah Blake   \n",
       "2           2  Elijah Blake   \n",
       "3           3  Elijah Blake   \n",
       "4           4  Elijah Blake   \n",
       "\n",
       "                                                 seq                song  \\\n",
       "0  No, no\\r\\nI ain't ever trapped out the bando\\r...            Everyday   \n",
       "1  The drinks go down and smoke goes up, I feel m...    Live Till We Die   \n",
       "2  She don't live on planet Earth no more\\r\\nShe ...       The Otherside   \n",
       "3  Trippin' off that Grigio, mobbin', lights low\\...               Pinot   \n",
       "4  I see a midnight panther, so gallant and so br...  Shadows & Diamonds   \n",
       "\n",
       "   label  \n",
       "0   0.63  \n",
       "1   0.63  \n",
       "2   0.24  \n",
       "3   0.54  \n",
       "4   0.37  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data.round(decimals=2)\n",
    "data.drop(labels=\"Unnamed: 0\", axis=1, inplace=True)\n",
    "data.rename(columns={\"seq\": \"lyrics\", \"label\": \"valency\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>song</th>\n",
       "      <th>valency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elijah Blake</td>\n",
       "      <td>No, no\\r\\nI ain't ever trapped out the bando\\r...</td>\n",
       "      <td>Everyday</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Elijah Blake</td>\n",
       "      <td>The drinks go down and smoke goes up, I feel m...</td>\n",
       "      <td>Live Till We Die</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Elijah Blake</td>\n",
       "      <td>She don't live on planet Earth no more\\r\\nShe ...</td>\n",
       "      <td>The Otherside</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elijah Blake</td>\n",
       "      <td>Trippin' off that Grigio, mobbin', lights low\\...</td>\n",
       "      <td>Pinot</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Elijah Blake</td>\n",
       "      <td>I see a midnight panther, so gallant and so br...</td>\n",
       "      <td>Shadows &amp; Diamonds</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         artist                                             lyrics  \\\n",
       "0  Elijah Blake  No, no\\r\\nI ain't ever trapped out the bando\\r...   \n",
       "1  Elijah Blake  The drinks go down and smoke goes up, I feel m...   \n",
       "2  Elijah Blake  She don't live on planet Earth no more\\r\\nShe ...   \n",
       "3  Elijah Blake  Trippin' off that Grigio, mobbin', lights low\\...   \n",
       "4  Elijah Blake  I see a midnight panther, so gallant and so br...   \n",
       "\n",
       "                 song  valency  \n",
       "0            Everyday     0.63  \n",
       "1    Live Till We Die     0.63  \n",
       "2       The Otherside     0.24  \n",
       "3               Pinot     0.54  \n",
       "4  Shadows & Diamonds     0.37  "
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check summary statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>song</th>\n",
       "      <th>valency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>158353</td>\n",
       "      <td>158353</td>\n",
       "      <td>158353</td>\n",
       "      <td>158353.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>14691</td>\n",
       "      <td>135991</td>\n",
       "      <td>99031</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Elvis Presley</td>\n",
       "      <td>Somewhere over the rainbow, way up high\\r\\nThe...</td>\n",
       "      <td>Have Yourself a Merry Little Christmas</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>821</td>\n",
       "      <td>167</td>\n",
       "      <td>162</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               artist                                             lyrics  \\\n",
       "count          158353                                             158353   \n",
       "unique          14691                                             135991   \n",
       "top     Elvis Presley  Somewhere over the rainbow, way up high\\r\\nThe...   \n",
       "freq              821                                                167   \n",
       "mean              NaN                                                NaN   \n",
       "std               NaN                                                NaN   \n",
       "min               NaN                                                NaN   \n",
       "25%               NaN                                                NaN   \n",
       "50%               NaN                                                NaN   \n",
       "75%               NaN                                                NaN   \n",
       "max               NaN                                                NaN   \n",
       "\n",
       "                                          song   valency  \n",
       "count                                   158353 158353.00  \n",
       "unique                                   99031       nan  \n",
       "top     Have Yourself a Merry Little Christmas       nan  \n",
       "freq                                       162       nan  \n",
       "mean                                       NaN      0.49  \n",
       "std                                        NaN      0.25  \n",
       "min                                        NaN      0.00  \n",
       "25%                                        NaN      0.29  \n",
       "50%                                        NaN      0.48  \n",
       "75%                                        NaN      0.69  \n",
       "max                                        NaN      1.00  "
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove cover songs and format decimal places for summary statistics display:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data.drop_duplicates(subset=['lyrics', 'song'])\n",
    "data.sort_values(by=['song', 'valency'], ascending=False, inplace=True) # to keep highest value valency \n",
    "data = data.drop_duplicates(subset='lyrics')\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x) # round everything to 2 decimal places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>song</th>\n",
       "      <th>valency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>135991</td>\n",
       "      <td>135991</td>\n",
       "      <td>135991</td>\n",
       "      <td>135991.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>10777</td>\n",
       "      <td>135991</td>\n",
       "      <td>95714</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Elvis Presley</td>\n",
       "      <td>There must be about 100 parties and I hit ever...</td>\n",
       "      <td>Intro</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>753</td>\n",
       "      <td>1</td>\n",
       "      <td>127</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               artist                                             lyrics  \\\n",
       "count          135991                                             135991   \n",
       "unique          10777                                             135991   \n",
       "top     Elvis Presley  There must be about 100 parties and I hit ever...   \n",
       "freq              753                                                  1   \n",
       "mean              NaN                                                NaN   \n",
       "std               NaN                                                NaN   \n",
       "min               NaN                                                NaN   \n",
       "25%               NaN                                                NaN   \n",
       "50%               NaN                                                NaN   \n",
       "75%               NaN                                                NaN   \n",
       "max               NaN                                                NaN   \n",
       "\n",
       "          song   valency  \n",
       "count   135991 135991.00  \n",
       "unique   95714       nan  \n",
       "top      Intro       nan  \n",
       "freq       127       nan  \n",
       "mean       NaN      0.50  \n",
       "std        NaN      0.25  \n",
       "min        NaN      0.00  \n",
       "25%        NaN      0.30  \n",
       "50%        NaN      0.50  \n",
       "75%        NaN      0.70  \n",
       "max        NaN      1.00  "
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spot-checking three random entries to confirm data integrity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>artist</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>song</th>\n",
       "      <th>valency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54911</td>\n",
       "      <td>Simon &amp;  Milo</td>\n",
       "      <td>Hello, this is Stacy, the computer\\nGood morni...</td>\n",
       "      <td>www.nevergetoveryou</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82479</td>\n",
       "      <td>Hippo Campus</td>\n",
       "      <td>See how the western kids\\r\\nHave silicon insid...</td>\n",
       "      <td>western kids</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82478</td>\n",
       "      <td>Hippo Campus</td>\n",
       "      <td>Wisconsin pines, collaborating with the day gl...</td>\n",
       "      <td>way it goes</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>82477</td>\n",
       "      <td>Hippo Campus</td>\n",
       "      <td>I see meaning where you don't, where you don't...</td>\n",
       "      <td>vines</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82476</td>\n",
       "      <td>Hippo Campus</td>\n",
       "      <td>My thoughts are a battlefield of sub-surreal a...</td>\n",
       "      <td>vacation</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135986</th>\n",
       "      <td>109667</td>\n",
       "      <td>The Beach Boys</td>\n",
       "      <td>Hi, this is Al this scene takes place at a typ...</td>\n",
       "      <td>\"Cassius\" Love Vs. \"Sonny\" Wilson</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135987</th>\n",
       "      <td>55096</td>\n",
       "      <td>Simple Minds</td>\n",
       "      <td>Cry cry cry\\r\\nCry like a baby\\r\\n\"see\" Moon \"...</td>\n",
       "      <td>\"C\" Moon Cry Like a Baby</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135988</th>\n",
       "      <td>41838</td>\n",
       "      <td>The Blues Brothers</td>\n",
       "      <td>Caught a ride into South Dakota\\r\\nWith two gi...</td>\n",
       "      <td>\"B\" Movie Box Car Blues</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135989</th>\n",
       "      <td>81217</td>\n",
       "      <td>The Gaslight Anthem</td>\n",
       "      <td>Have you seen my hands?\\nJust look at 'em shak...</td>\n",
       "      <td>\"45\"</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135990</th>\n",
       "      <td>38621</td>\n",
       "      <td>U2</td>\n",
       "      <td>I waited patiently for the Lord\\nHe inclined a...</td>\n",
       "      <td>\"40\"</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135991 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index               artist  \\\n",
       "0        54911        Simon &  Milo   \n",
       "1        82479         Hippo Campus   \n",
       "2        82478         Hippo Campus   \n",
       "3        82477         Hippo Campus   \n",
       "4        82476         Hippo Campus   \n",
       "...        ...                  ...   \n",
       "135986  109667       The Beach Boys   \n",
       "135987   55096         Simple Minds   \n",
       "135988   41838   The Blues Brothers   \n",
       "135989   81217  The Gaslight Anthem   \n",
       "135990   38621                   U2   \n",
       "\n",
       "                                                   lyrics  \\\n",
       "0       Hello, this is Stacy, the computer\\nGood morni...   \n",
       "1       See how the western kids\\r\\nHave silicon insid...   \n",
       "2       Wisconsin pines, collaborating with the day gl...   \n",
       "3       I see meaning where you don't, where you don't...   \n",
       "4       My thoughts are a battlefield of sub-surreal a...   \n",
       "...                                                   ...   \n",
       "135986  Hi, this is Al this scene takes place at a typ...   \n",
       "135987  Cry cry cry\\r\\nCry like a baby\\r\\n\"see\" Moon \"...   \n",
       "135988  Caught a ride into South Dakota\\r\\nWith two gi...   \n",
       "135989  Have you seen my hands?\\nJust look at 'em shak...   \n",
       "135990  I waited patiently for the Lord\\nHe inclined a...   \n",
       "\n",
       "                                     song  valency  \n",
       "0                     www.nevergetoveryou     0.68  \n",
       "1                            western kids     0.52  \n",
       "2                             way it goes     0.52  \n",
       "3                                   vines     0.66  \n",
       "4                                vacation     0.55  \n",
       "...                                   ...      ...  \n",
       "135986  \"Cassius\" Love Vs. \"Sonny\" Wilson     0.49  \n",
       "135987           \"C\" Moon Cry Like a Baby     0.77  \n",
       "135988            \"B\" Movie Box Car Blues     0.50  \n",
       "135989                               \"45\"     0.42  \n",
       "135990                               \"40\"     0.32  \n",
       "\n",
       "[135991 rows x 5 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.reset_index() \n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempting sentiment classification using Vader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk import tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading a song lyrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every time I turn my back I get the feeling that\r\n",
      "I'm 'bout to take a shot to the skully with a bat\r\n"
     ]
    }
   ],
   "source": [
    "lyrics = data.at[201, 'lyrics'].strip()\n",
    "#text = tokenize.sent_tokenize(lyrics)[0]\n",
    "print(lyrics[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysing valency and extracting compund score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('negative', -0.8814)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def valency(text):\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    ss = sid.polarity_scores(text)\n",
    "    #ss.pop('compound')\n",
    "    compound_score = ss.get('compound')\n",
    "    if compound_score > 0.3 and compound_score <= 1:\n",
    "        valency = 'positive'\n",
    "    elif compound_score >= -1 and compound_score < -0.3:\n",
    "        valency = 'negative'\n",
    "    else:\n",
    "        valency = 'neutral'\n",
    "    return valency, compound_score\n",
    "    \n",
    "valency(lyrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User situtation test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('positive', 0.6239), ('neutral', 0.0))"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = \"Today is finally my day off! The weather is amazing and I'm going to the beach\"\n",
    "s2 = \"Today is finally my day off! The weather is [] and I'm going to the beach\"\n",
    "valency(s1), valency(s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is not great so a diiferent classisifier needed, possibly trained on NLTK moview reviews corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If max score required instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max_value = max(ss.values())\n",
    "#max_value\n",
    "#max_key = [k for k, v in ss.items() if v == max_value][0]\n",
    "#max_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training classifier to assing one of the Brown corpus categories to an arbitrary text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import brown, stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "categories = ['adventure', 'hobbies', 'humor', 'mystery', 'romance']\n",
    "#cfd = nltk.ConditionalFreqDist((genre, word) for genre in brown.categories() for word in brown.words(categories=genre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist1 = nltk.FreqDist([lemmatizer.lemmatize(word) for word in brown.words(categories='humor')\n",
    "                        if word.isalnum() and word.lower() not in stopwords.words('english')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module nltk.corpus.reader.reviews in nltk.corpus.reader:\n",
      "\n",
      "NAME\n",
      "    nltk.corpus.reader.reviews - CorpusReader for reviews corpora (syntax based on Customer Review Corpus).\n",
      "\n",
      "DESCRIPTION\n",
      "    - Customer Review Corpus information -\n",
      "    Annotated by: Minqing Hu and Bing Liu, 2004.\n",
      "        Department of Computer Sicence\n",
      "        University of Illinois at Chicago\n",
      "    \n",
      "    Contact: Bing Liu, liub@cs.uic.edu\n",
      "            http://www.cs.uic.edu/~liub\n",
      "    \n",
      "    Distributed with permission.\n",
      "    \n",
      "    The \"product_reviews_1\" and \"product_reviews_2\" datasets respectively contain\n",
      "    annotated customer reviews of 5 and 9 products from amazon.com.\n",
      "    \n",
      "    Related papers:\n",
      "    \n",
      "    - Minqing Hu and Bing Liu. \"Mining and summarizing customer reviews\".\n",
      "        Proceedings of the ACM SIGKDD International Conference on Knowledge\n",
      "        Discovery & Data Mining (KDD-04), 2004.\n",
      "    \n",
      "    - Minqing Hu and Bing Liu. \"Mining Opinion Features in Customer Reviews\".\n",
      "        Proceedings of Nineteeth National Conference on Artificial Intelligence\n",
      "        (AAAI-2004), 2004.\n",
      "    \n",
      "    - Xiaowen Ding, Bing Liu and Philip S. Yu. \"A Holistic Lexicon-Based Appraoch to\n",
      "        Opinion Mining.\" Proceedings of First ACM International Conference on Web\n",
      "        Search and Data Mining (WSDM-2008), Feb 11-12, 2008, Stanford University,\n",
      "        Stanford, California, USA.\n",
      "    \n",
      "    Symbols used in the annotated reviews:\n",
      "    \n",
      "        [t] : the title of the review: Each [t] tag starts a review.\n",
      "        xxxx[+|-n]: xxxx is a product feature.\n",
      "        [+n]: Positive opinion, n is the opinion strength: 3 strongest, and 1 weakest.\n",
      "              Note that the strength is quite subjective.\n",
      "              You may want ignore it, but only considering + and -\n",
      "        [-n]: Negative opinion\n",
      "        ##  : start of each sentence. Each line is a sentence.\n",
      "        [u] : feature not appeared in the sentence.\n",
      "        [p] : feature not appeared in the sentence. Pronoun resolution is needed.\n",
      "        [s] : suggestion or recommendation.\n",
      "        [cc]: comparison with a competing product from a different brand.\n",
      "        [cs]: comparison with a competing product from the same brand.\n",
      "    \n",
      "    Note: Some of the files (e.g. \"ipod.txt\", \"Canon PowerShot SD500.txt\") do not\n",
      "        provide separation between different reviews. This is due to the fact that\n",
      "        the dataset was specifically designed for aspect/feature-based sentiment\n",
      "        analysis, for which sentence-level annotation is sufficient. For document-\n",
      "        level classification and analysis, this peculiarity should be taken into\n",
      "        consideration.\n",
      "\n",
      "CLASSES\n",
      "    builtins.object\n",
      "        Review\n",
      "        ReviewLine\n",
      "    nltk.corpus.reader.api.CorpusReader(builtins.object)\n",
      "        ReviewsCorpusReader\n",
      "    \n",
      "    class Review(builtins.object)\n",
      "     |  Review(title=None, review_lines=None)\n",
      "     |  \n",
      "     |  A Review is the main block of a ReviewsCorpusReader.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, title=None, review_lines=None)\n",
      "     |      :param title: the title of the review.\n",
      "     |      :param review_lines: the list of the ReviewLines that belong to the Review.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  add_line(self, review_line)\n",
      "     |      Add a line (ReviewLine) to the review.\n",
      "     |      \n",
      "     |      :param review_line: a ReviewLine instance that belongs to the Review.\n",
      "     |  \n",
      "     |  features(self)\n",
      "     |      Return a list of features in the review. Each feature is a tuple made of\n",
      "     |      the specific item feature and the opinion strength about that feature.\n",
      "     |      \n",
      "     |      :return: all features of the review as a list of tuples (feat, score).\n",
      "     |      :rtype: list(tuple)\n",
      "     |  \n",
      "     |  sents(self)\n",
      "     |      Return all tokenized sentences in the review.\n",
      "     |      \n",
      "     |      :return: all sentences of the review as lists of tokens.\n",
      "     |      :rtype: list(list(str))\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class ReviewLine(builtins.object)\n",
      "     |  ReviewLine(sent, features=None, notes=None)\n",
      "     |  \n",
      "     |  A ReviewLine represents a sentence of the review, together with (optional)\n",
      "     |  annotations of its features and notes about the reviewed item.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, sent, features=None, notes=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class ReviewsCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  ReviewsCorpusReader(root, fileids, word_tokenizer=WordPunctTokenizer(pattern='\\\\w+|[^\\\\w\\\\s]+', gaps=False, discard_empty=True, flags=re.UNICODE|re.MULTILINE|re.DOTALL), encoding='utf8')\n",
      "     |  \n",
      "     |  Reader for the Customer Review Data dataset by Hu, Liu (2004).\n",
      "     |  Note: we are not applying any sentence tokenization at the moment, just word\n",
      "     |  tokenization.\n",
      "     |  \n",
      "     |      >>> from nltk.corpus import product_reviews_1\n",
      "     |      >>> camera_reviews = product_reviews_1.reviews('Canon_G3.txt')\n",
      "     |      >>> review = camera_reviews[0]\n",
      "     |      >>> review.sents()[0]\n",
      "     |      ['i', 'recently', 'purchased', 'the', 'canon', 'powershot', 'g3', 'and', 'am',\n",
      "     |      'extremely', 'satisfied', 'with', 'the', 'purchase', '.']\n",
      "     |      >>> review.features()\n",
      "     |      [('canon powershot g3', '+3'), ('use', '+2'), ('picture', '+2'),\n",
      "     |      ('picture quality', '+1'), ('picture quality', '+1'), ('camera', '+2'),\n",
      "     |      ('use', '+2'), ('feature', '+1'), ('picture quality', '+3'), ('use', '+1'),\n",
      "     |      ('option', '+1')]\n",
      "     |  \n",
      "     |  We can also reach the same information directly from the stream:\n",
      "     |  \n",
      "     |      >>> product_reviews_1.features('Canon_G3.txt')\n",
      "     |      [('canon powershot g3', '+3'), ('use', '+2'), ...]\n",
      "     |  \n",
      "     |  We can compute stats for specific product features:\n",
      "     |  \n",
      "     |      >>> n_reviews = len([(feat,score) for (feat,score) in product_reviews_1.features('Canon_G3.txt') if feat=='picture'])\n",
      "     |      >>> tot = sum([int(score) for (feat,score) in product_reviews_1.features('Canon_G3.txt') if feat=='picture'])\n",
      "     |      >>> mean = tot / n_reviews\n",
      "     |      >>> print(n_reviews, tot, mean)\n",
      "     |      15 24 1.6\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ReviewsCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, word_tokenizer=WordPunctTokenizer(pattern='\\\\w+|[^\\\\w\\\\s]+', gaps=False, discard_empty=True, flags=re.UNICODE|re.MULTILINE|re.DOTALL), encoding='utf8')\n",
      "     |      :param root: The root directory for the corpus.\n",
      "     |      :param fileids: a list or regexp specifying the fileids in the corpus.\n",
      "     |      :param word_tokenizer: a tokenizer for breaking sentences or paragraphs\n",
      "     |          into words. Default: `WordPunctTokenizer`\n",
      "     |      :param encoding: the encoding that should be used to read the corpus.\n",
      "     |  \n",
      "     |  features(self, fileids=None)\n",
      "     |      Return a list of features. Each feature is a tuple made of the specific\n",
      "     |      item feature and the opinion strength about that feature.\n",
      "     |      \n",
      "     |      :param fileids: a list or regexp specifying the ids of the files whose\n",
      "     |          features have to be returned.\n",
      "     |      :return: all features for the item(s) in the given file(s).\n",
      "     |      :rtype: list(tuple)\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |      :param fileids: a list or regexp specifying the fileids of the files that\n",
      "     |          have to be returned as a raw string.\n",
      "     |      :return: the given file(s) as a single string.\n",
      "     |      :rtype: str\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README.txt file.\n",
      "     |  \n",
      "     |  reviews(self, fileids=None)\n",
      "     |      Return all the reviews as a list of Review objects. If `fileids` is\n",
      "     |      specified, return all the reviews from each of the specified files.\n",
      "     |      \n",
      "     |      :param fileids: a list or regexp specifying the ids of the files whose\n",
      "     |          reviews have to be returned.\n",
      "     |      :return: the given file(s) as a list of reviews.\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |      Return all sentences in the corpus or in the specified files.\n",
      "     |      \n",
      "     |      :param fileids: a list or regexp specifying the ids of the files whose\n",
      "     |          sentences have to be returned.\n",
      "     |      :return: the given file(s) as a list of sentences, each encoded as a\n",
      "     |          list of word strings.\n",
      "     |      :rtype: list(list(str))\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |      Return all words and punctuation symbols in the corpus or in the specified\n",
      "     |      files.\n",
      "     |      \n",
      "     |      :param fileids: a list or regexp specifying the ids of the files whose\n",
      "     |          words have to be returned.\n",
      "     |      :return: the given file(s) as a list of words and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  CorpusView = <class 'nltk.corpus.reader.util.StreamBackedCorpusView'>\n",
      "     |      A 'view' of a corpus file, which acts like a sequence of tokens:\n",
      "     |      it can be accessed by index, iterated over, etc.  However, the\n",
      "     |      tokens are only constructed as-needed -- the entire corpus is\n",
      "     |      never stored in memory at once.\n",
      "     |      \n",
      "     |      The constructor to ``StreamBackedCorpusView`` takes two arguments:\n",
      "     |      a corpus fileid (specified as a string or as a ``PathPointer``);\n",
      "     |      and a block reader.  A \"block reader\" is a function that reads\n",
      "     |      zero or more tokens from a stream, and returns them as a list.  A\n",
      "     |      very simple example of a block reader is:\n",
      "     |      \n",
      "     |          >>> def simple_block_reader(stream):\n",
      "     |          ...     return stream.readline().split()\n",
      "     |      \n",
      "     |      This simple block reader reads a single line at a time, and\n",
      "     |      returns a single token (consisting of a string) for each\n",
      "     |      whitespace-separated substring on the line.\n",
      "     |      \n",
      "     |      When deciding how to define the block reader for a given\n",
      "     |      corpus, careful consideration should be given to the size of\n",
      "     |      blocks handled by the block reader.  Smaller block sizes will\n",
      "     |      increase the memory requirements of the corpus view's internal\n",
      "     |      data structures (by 2 integers per block).  On the other hand,\n",
      "     |      larger block sizes may decrease performance for random access to\n",
      "     |      the corpus.  (But note that larger block sizes will *not*\n",
      "     |      decrease performance for iteration.)\n",
      "     |      \n",
      "     |      Internally, ``CorpusView`` maintains a partial mapping from token\n",
      "     |      index to file position, with one entry per block.  When a token\n",
      "     |      with a given index *i* is requested, the ``CorpusView`` constructs\n",
      "     |      it as follows:\n",
      "     |      \n",
      "     |        1. First, it searches the toknum/filepos mapping for the token\n",
      "     |           index closest to (but less than or equal to) *i*.\n",
      "     |      \n",
      "     |        2. Then, starting at the file position corresponding to that\n",
      "     |           index, it reads one block at a time using the block reader\n",
      "     |           until it reaches the requested token.\n",
      "     |      \n",
      "     |      The toknum/filepos mapping is created lazily: it is initially\n",
      "     |      empty, but every time a new block is read, the block's\n",
      "     |      initial token is added to the mapping.  (Thus, the toknum/filepos\n",
      "     |      map has one entry per block.)\n",
      "     |      \n",
      "     |      In order to increase efficiency for random access patterns that\n",
      "     |      have high degrees of locality, the corpus view may cache one or\n",
      "     |      more blocks.\n",
      "     |      \n",
      "     |      :note: Each ``CorpusView`` object internally maintains an open file\n",
      "     |          object for its underlying corpus file.  This file should be\n",
      "     |          automatically closed when the ``CorpusView`` is garbage collected,\n",
      "     |          but if you wish to close it manually, use the ``close()``\n",
      "     |          method.  If you access a ``CorpusView``'s items after it has been\n",
      "     |          closed, the file object will be automatically re-opened.\n",
      "     |      \n",
      "     |      :warning: If the contents of the file are modified during the\n",
      "     |          lifetime of the ``CorpusView``, then the ``CorpusView``'s behavior\n",
      "     |          is undefined.\n",
      "     |      \n",
      "     |      :warning: If a unicode encoding is specified when constructing a\n",
      "     |          ``CorpusView``, then the block reader may only call\n",
      "     |          ``stream.seek()`` with offsets that have been returned by\n",
      "     |          ``stream.tell()``; in particular, calling ``stream.seek()`` with\n",
      "     |          relative offsets, or with offsets based on string lengths, may\n",
      "     |          lead to incorrect behavior.\n",
      "     |      \n",
      "     |      :ivar _block_reader: The function used to read\n",
      "     |          a single block from the underlying file stream.\n",
      "     |      :ivar _toknum: A list containing the token index of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          token index of the first token in block ``i``.  Together\n",
      "     |          with ``_filepos``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _filepos: A list containing the file position of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          file position of the first character in block ``i``.  Together\n",
      "     |          with ``_toknum``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _stream: The stream used to access the underlying corpus file.\n",
      "     |      :ivar _len: The total number of tokens in the corpus, if known;\n",
      "     |          or None, if the number of tokens is not yet known.\n",
      "     |      :ivar _eofpos: The character position of the last character in the\n",
      "     |          file.  This is calculated when the corpus view is initialized,\n",
      "     |          and is used to decide when the end of file has been reached.\n",
      "     |      :ivar _cache: A cache of the most recently read block.  It\n",
      "     |         is encoded as a tuple (start_toknum, end_toknum, tokens), where\n",
      "     |         start_toknum is the token index of the first token in the block;\n",
      "     |         end_toknum is the token index of the first token not in the\n",
      "     |         block; and tokens is a list of the tokens in the block.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "FUNCTIONS\n",
      "    reduce(...)\n",
      "        reduce(function, sequence[, initial]) -> value\n",
      "        \n",
      "        Apply a function of two arguments cumulatively to the items of a sequence,\n",
      "        from left to right, so as to reduce the sequence to a single value.\n",
      "        For example, reduce(lambda x, y: x+y, [1, 2, 3, 4, 5]) calculates\n",
      "        ((((1+2)+3)+4)+5).  If initial is present, it is placed before the items\n",
      "        of the sequence in the calculation, and serves as a default when the\n",
      "        sequence is empty.\n",
      "\n",
      "DATA\n",
      "    FEATURES = re.compile('((?:(?:\\\\w+\\\\s)+)?\\\\w+)\\\\[((?:\\\\+|\\\\-)\\\\d)\\\\]')\n",
      "    NOTES = re.compile('\\\\[(?!t)(p|u|s|cc|cs)\\\\]')\n",
      "    SENT = re.compile('##(.*)$')\n",
      "    TITLE = re.compile('^\\\\[t\\\\](.*)$')\n",
      "\n",
      "FILE\n",
      "    c:\\users\\ad\\anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\reviews.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(nltk.corpus.reader.reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('said', 87),\n",
       " ('one', 65),\n",
       " ('would', 56),\n",
       " ('time', 50),\n",
       " ('thing', 40),\n",
       " ('even', 38),\n",
       " ('like', 34),\n",
       " ('could', 30),\n",
       " ('way', 29),\n",
       " ('year', 29)]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist1.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist2 = nltk.FreqDist([lemmatizer.lemmatize(word) for word in brown.words(categories='mystery')\n",
    "                    if word.isalnum() and word.lower() not in stopwords.words('english')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('said', 202),\n",
       " ('would', 186),\n",
       " ('one', 175),\n",
       " ('back', 157),\n",
       " ('could', 141),\n",
       " ('like', 136),\n",
       " ('man', 106),\n",
       " ('get', 101),\n",
       " ('know', 93),\n",
       " ('time', 87)]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist2.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "\n",
    "for category in brown.categories():\n",
    "    for fileid in brown.fileids(category):\n",
    "        if category in categories:\n",
    "            dataset.append((brown.words(fileids = fileid), category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting features from lyrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokens = [tokenize.sent_tokenize(x) for x in data['lyrics']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#text = tokens[0][8]\n",
    "#text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
