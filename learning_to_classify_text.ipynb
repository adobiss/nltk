{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Supervised classification:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gender identification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'last_letter': 'k'}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "def gender_features(name):\n",
    "    return {'last_letter': name[-1]\n",
    "            #, 'first_letter': word[0]\n",
    "            #, 'name_length': len(word)\n",
    "           } # builds a feature set: human-readable feature name and value pair\n",
    "\n",
    "gender_features('Shrek')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features2(name):\n",
    "    features = {}\n",
    "    features['first_letter'] = name[0].lower()\n",
    "    features['last_letter'] = name[-1].lower()\n",
    "    for x in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features['count({})'.format(x)] = name.lower().count(x)\n",
    "        features['has({})'.format(x)] = (x in name.lower())\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Cristen', 'female'),\n",
       " ('Moore', 'male'),\n",
       " ('Ursala', 'female'),\n",
       " ('Alston', 'male'),\n",
       " ('Kellen', 'female')]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import names\n",
    "\n",
    "labeled_names = ([(x, 'male') for x in names.words('male.txt')] +\n",
    "                [(x, 'female') for x in names.words('female.txt')])\n",
    "\n",
    "import random\n",
    "random.shuffle(labeled_names)\n",
    "labeled_names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'female': 5001, 'male': 2943})"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.FreqDist([y for x, y in labeled_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When feature set is relatively small\n",
    "\n",
    "#featuresets = [(gender_features2(x), y) for x, y in labeled_names]\n",
    "#train_set, test_set = featuresets[500:], featuresets[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When feature set is large\n",
    "\n",
    "from nltk.classify import apply_features\n",
    "\n",
    "train_set = apply_features(gender_features2, labeled_names[500:])\n",
    "test_set = apply_features(gender_features2, labeled_names[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7944, 7444)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(featuresets), len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trinity is a female\n"
     ]
    }
   ],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "name = 'Trinity'\n",
    "print('{} is a '.format(name) + classifier.classify(gender_features2(name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.752\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find most the most effective features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             last_letter = 'a'            female : male   =     34.4 : 1.0\n",
      "             last_letter = 'k'              male : female =     30.0 : 1.0\n",
      "             last_letter = 'f'              male : female =     17.1 : 1.0\n",
      "             last_letter = 'p'              male : female =     12.4 : 1.0\n",
      "             last_letter = 'v'              male : female =     11.1 : 1.0\n",
      "                count(v) = 2              female : male   =      9.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(6) # likelihood ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Choosing the right features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features2(name):\n",
    "    features = {}\n",
    "    features['first_letter'] = name[0].lower()\n",
    "    features['last_letter'] = name[-1].lower()\n",
    "    for x in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features['count({})'.format(x)] = name.lower().count(x)\n",
    "        features['has({})'.format(x)] = (x in name.lower())\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#gender_features2('John')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_names = labeled_names[1500:]\n",
    "devtest_names = labeled_names[500:1500]\n",
    "test_names = labeled_names[:500]\n",
    "#len(train_names), len(devtest_names), len(test_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply features to the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = apply_features(gender_features, train_names)\n",
    "devtest_set = apply_features(gender_features, devtest_names)\n",
    "test_set = apply_features(gender_features, test_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.762\n"
     ]
    }
   ],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, devtest_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct=female  guess=male    name=Adel                          \n",
      "correct=female  guess=male    name=Ailyn                         \n",
      "correct=female  guess=male    name=Allison                       \n",
      "correct=female  guess=male    name=Angil                         \n",
      "correct=female  guess=male    name=Annabel                       \n",
      "correct=female  guess=male    name=Anne-Mar                      \n",
      "correct=female  guess=male    name=Arabel                        \n",
      "correct=female  guess=male    name=Arlen                         \n",
      "correct=female  guess=male    name=Berget                        \n",
      "correct=female  guess=male    name=Bliss                         \n"
     ]
    }
   ],
   "source": [
    "errors = []\n",
    "\n",
    "for x, y in devtest_names:\n",
    "    guess = classifier.classify(gender_features(x))\n",
    "    if guess != y:\n",
    "        errors.append((y, guess, x))\n",
    "        \n",
    "for (y, guess, x) in sorted(errors)[:10]:\n",
    "    print('correct={:<8}' 'guess={:<8s}' 'name={:<30}'.format(y, guess, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'suffix1': 'n', 'suffix2': 'yn'}"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gender_features(name):\n",
    "    return {'suffix1': name[-1],\n",
    "            'suffix2': name[-2:]}\n",
    "\n",
    "gender_features('Ailyn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrain the classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.787\n"
     ]
    }
   ],
   "source": [
    "train_set = apply_features(gender_features, train_names)\n",
    "devtest_set = apply_features(gender_features, devtest_names)\n",
    "test_set = apply_features(gender_features, test_names)\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, devtest_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                 suffix2 = 'na'           female : male   =     88.7 : 1.0\n",
      "                 suffix2 = 'la'           female : male   =     63.6 : 1.0\n",
      "                 suffix2 = 'us'             male : female =     61.1 : 1.0\n",
      "                 suffix2 = 'ia'           female : male   =     32.8 : 1.0\n",
      "                 suffix1 = 'a'            female : male   =     32.3 : 1.0\n",
      "                 suffix2 = 'sa'           female : male   =     30.9 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final accuracy test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.758\n",
      "Neo is a female\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, test_set))\n",
    "name = 'Neo'\n",
    "print('{} is a '.format(name) + classifier.classify(gender_features2(name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
