{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Grammatical dilemmas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ambiguity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, re, pprint\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CFG - context free grammar\n",
    "\n",
    "groucho_grammar = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "PP -> P NP\n",
    "NP -> Det N | Det N PP | 'I'\n",
    "VP -> V NP | VP PP\n",
    "Det -> 'an' | 'my'\n",
    "N -> 'elephant' | 'pajamas'\n",
    "V -> 'shot'\n",
    "P -> 'in'\n",
    "\"\"\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'shot', 'an', 'elephant', 'in', 'my', 'pajamas']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I shot an elephant in my pajamas\"\n",
    "sent = word_tokenize(text)\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (VP (V shot) (NP (Det an) (N elephant)))\n",
      "    (PP (P in) (NP (Det my) (N pajamas)))))\n",
      "(S\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (V shot)\n",
      "    (NP (Det an) (N elephant) (PP (P in) (NP (Det my) (N pajamas))))))\n"
     ]
    }
   ],
   "source": [
    "parser = nltk.ChartParser(groucho_grammar)\n",
    "for x in parser.parse(sent):\n",
    "    print(x)\n",
    "    #print(x.draw())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Fighting', 'NN'), ('animals', 'NNS'), ('could', 'MD'), ('be', 'BE'), ('dangerous', 'JJ'), ('.', '.')]\n",
      "[('Visiting', 'NN'), ('relatives', 'NNS'), ('can', 'MD'), ('be', 'BE'), ('tiresome', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "from pickle import load\n",
    "input = open('t2.pkl', 'rb') # binary format for reading\n",
    "tagger = load(input)\n",
    "input.close()\n",
    "\n",
    "text2 = 'Fighting animals could be dangerous. Visiting relatives can be tiresome.' # ambiguous pos - JJ vs. NN \n",
    "\n",
    "for x in sent_tokenize(text2):\n",
    "    print(tagger.tag(word_tokenize(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Context free grammar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar1 = nltk.CFG.fromstring(\"\"\"\n",
    "  S -> NP VP\n",
    "  VP -> V NP | V NP PP\n",
    "  PP -> P NP\n",
    "  V -> \"saw\" | \"ate\" | \"walked\"\n",
    "  NP -> \"John\" | \"Mary\" | \"Bob\" | Det N | Det N PP\n",
    "  Det -> \"a\" | \"an\" | \"the\" | \"my\"\n",
    "  N -> \"man\" | \"dog\" | \"cat\" | \"telescope\" | \"park\"\n",
    "  P -> \"in\" | \"on\" | \"by\" | \"with\"\n",
    "  \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP Mary) (VP (V saw) (NP Bob)))\n"
     ]
    }
   ],
   "source": [
    "sent2 = 'Mary saw Bob'.split() # simplified word tokenisation\n",
    "rd_parser = nltk.RecursiveDescentParser(grammar1)\n",
    "for x in rd_parser.parse(sent2):\n",
    "    #print(x.draw())\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'dog', 'saw', 'a', 'man', 'in', 'the', 'park']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent3 = 'The dog saw a man in the park'.split()\n",
    "sent3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('under',)]\n",
      "[('with',)]\n",
      "[('in',)]\n",
      "[('under',), ('with',)]\n",
      "[('ate',)]\n",
      "[('saw',)]\n",
      "[('dog',)]\n",
      "[('telescope',)]\n",
      "[('park',)]\n",
      "[('dog',), ('telescope',)]\n",
      "[('man',)]\n",
      "[('park',), ('dog',), ('telescope',)]\n",
      "[('the',)]\n",
      "[('a',)]\n",
      "[(V, NP)]\n",
      "[(V,)]\n",
      "[(V, NP, PP)]\n",
      "[(V, NP), (V,)]\n",
      "[(Det, N, PP)]\n",
      "[(Det, N)]\n",
      "S [(NP, VP)]\n",
      "NP [(Det, N, PP), (Det, N)]\n",
      "VP [(V, NP, PP), (V, NP), (V,)]\n",
      "PP [(P, NP)]\n",
      "NP [('I',)]\n",
      "Det [('the',), ('a',)]\n",
      "N [('man',), ('park',), ('dog',), ('telescope',)]\n",
      "V [('ate',), ('saw',)]\n",
      "P [('in',), ('under',), ('with',)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AD\\anaconda3\\lib\\tkinter\\__init__.py\", line 1883, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\AD\\anaconda3\\lib\\site-packages\\nltk\\draw\\cfg.py\", line 522, in _apply\n",
      "    productions = self._parse_productions()\n",
      "  File \"C:\\Users\\AD\\anaconda3\\lib\\site-packages\\nltk\\draw\\cfg.py\", line 492, in _parse_productions\n",
      "    productions += _read_cfg_production(line)\n",
      "  File \"C:\\Users\\AD\\anaconda3\\lib\\site-packages\\nltk\\grammar.py\", line 1315, in _read_cfg_production\n",
      "    return _read_production(input, standard_nonterm_parser)\n",
      "  File \"C:\\Users\\AD\\anaconda3\\lib\\site-packages\\nltk\\grammar.py\", line 1353, in _read_production\n",
      "    raise ValueError(\"Expected an arrow\")\n",
      "ValueError: Expected an arrow\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AD\\anaconda3\\lib\\tkinter\\__init__.py\", line 1883, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\AD\\anaconda3\\lib\\site-packages\\nltk\\draw\\cfg.py\", line 522, in _apply\n",
      "    productions = self._parse_productions()\n",
      "  File \"C:\\Users\\AD\\anaconda3\\lib\\site-packages\\nltk\\draw\\cfg.py\", line 492, in _parse_productions\n",
      "    productions += _read_cfg_production(line)\n",
      "  File \"C:\\Users\\AD\\anaconda3\\lib\\site-packages\\nltk\\grammar.py\", line 1315, in _read_cfg_production\n",
      "    return _read_production(input, standard_nonterm_parser)\n",
      "  File \"C:\\Users\\AD\\anaconda3\\lib\\site-packages\\nltk\\grammar.py\", line 1353, in _read_production\n",
      "    raise ValueError(\"Expected an arrow\")\n",
      "ValueError: Expected an arrow\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AD\\anaconda3\\lib\\tkinter\\__init__.py\", line 1883, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\AD\\anaconda3\\lib\\site-packages\\nltk\\draw\\cfg.py\", line 522, in _apply\n",
      "    productions = self._parse_productions()\n",
      "  File \"C:\\Users\\AD\\anaconda3\\lib\\site-packages\\nltk\\draw\\cfg.py\", line 492, in _parse_productions\n",
      "    productions += _read_cfg_production(line)\n",
      "  File \"C:\\Users\\AD\\anaconda3\\lib\\site-packages\\nltk\\grammar.py\", line 1315, in _read_cfg_production\n",
      "    return _read_production(input, standard_nonterm_parser)\n",
      "  File \"C:\\Users\\AD\\anaconda3\\lib\\site-packages\\nltk\\grammar.py\", line 1353, in _read_production\n",
      "    raise ValueError(\"Expected an arrow\")\n",
      "ValueError: Expected an arrow\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AD\\anaconda3\\lib\\tkinter\\__init__.py\", line 1883, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\AD\\anaconda3\\lib\\site-packages\\nltk\\draw\\cfg.py\", line 522, in _apply\n",
      "    productions = self._parse_productions()\n",
      "  File \"C:\\Users\\AD\\anaconda3\\lib\\site-packages\\nltk\\draw\\cfg.py\", line 492, in _parse_productions\n",
      "    productions += _read_cfg_production(line)\n",
      "  File \"C:\\Users\\AD\\anaconda3\\lib\\site-packages\\nltk\\grammar.py\", line 1315, in _read_cfg_production\n",
      "    return _read_production(input, standard_nonterm_parser)\n",
      "  File \"C:\\Users\\AD\\anaconda3\\lib\\site-packages\\nltk\\grammar.py\", line 1353, in _read_production\n",
      "    raise ValueError(\"Expected an arrow\")\n",
      "ValueError: Expected an arrow\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AD\\anaconda3\\lib\\tkinter\\__init__.py\", line 1883, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\AD\\anaconda3\\lib\\site-packages\\nltk\\draw\\cfg.py\", line 522, in _apply\n",
      "    productions = self._parse_productions()\n",
      "  File \"C:\\Users\\AD\\anaconda3\\lib\\site-packages\\nltk\\draw\\cfg.py\", line 492, in _parse_productions\n",
      "    productions += _read_cfg_production(line)\n",
      "  File \"C:\\Users\\AD\\anaconda3\\lib\\site-packages\\nltk\\grammar.py\", line 1315, in _read_cfg_production\n",
      "    return _read_production(input, standard_nonterm_parser)\n",
      "  File \"C:\\Users\\AD\\anaconda3\\lib\\site-packages\\nltk\\grammar.py\", line 1353, in _read_production\n",
      "    raise ValueError(\"Expected an arrow\")\n",
      "ValueError: Expected an arrow\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AD\\anaconda3\\lib\\tkinter\\__init__.py\", line 1883, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\AD\\anaconda3\\lib\\site-packages\\nltk\\draw\\cfg.py\", line 522, in _apply\n",
      "    productions = self._parse_productions()\n",
      "  File \"C:\\Users\\AD\\anaconda3\\lib\\site-packages\\nltk\\draw\\cfg.py\", line 492, in _parse_productions\n",
      "    productions += _read_cfg_production(line)\n",
      "  File \"C:\\Users\\AD\\anaconda3\\lib\\site-packages\\nltk\\grammar.py\", line 1315, in _read_cfg_production\n",
      "    return _read_production(input, standard_nonterm_parser)\n",
      "  File \"C:\\Users\\AD\\anaconda3\\lib\\site-packages\\nltk\\grammar.py\", line 1353, in _read_production\n",
      "    raise ValueError(\"Expected an arrow\")\n",
      "ValueError: Expected an arrow\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AD\\anaconda3\\lib\\tkinter\\__init__.py\", line 1883, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\AD\\anaconda3\\lib\\site-packages\\nltk\\draw\\cfg.py\", line 522, in _apply\n",
      "    productions = self._parse_productions()\n",
      "  File \"C:\\Users\\AD\\anaconda3\\lib\\site-packages\\nltk\\draw\\cfg.py\", line 492, in _parse_productions\n",
      "    productions += _read_cfg_production(line)\n",
      "  File \"C:\\Users\\AD\\anaconda3\\lib\\site-packages\\nltk\\grammar.py\", line 1315, in _read_cfg_production\n",
      "    return _read_production(input, standard_nonterm_parser)\n",
      "  File \"C:\\Users\\AD\\anaconda3\\lib\\site-packages\\nltk\\grammar.py\", line 1353, in _read_production\n",
      "    raise ValueError(\"Expected an arrow\")\n",
      "ValueError: Expected an arrow\n"
     ]
    }
   ],
   "source": [
    "nltk.app.rdparser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writing your own grammar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing 'the dog saw a man in the park'\n",
      "Found a parse:\n",
      "(S\n",
      "  (NP (Det the) (N dog))\n",
      "  (VP\n",
      "    (V saw)\n",
      "    (NP (Det a) (N man) (PP (P in) (NP (Det the) (N park))))))\n",
      "(S\n",
      "  (NP (Det the) (N dog))\n",
      "  (VP\n",
      "    (V saw)\n",
      "    (NP (Det a) (N man) (PP (P in) (NP (Det the) (N park))))))\n",
      "Found a parse:\n",
      "(S\n",
      "  (NP (Det the) (N dog))\n",
      "  (VP\n",
      "    (V saw)\n",
      "    (NP (Det a) (N man))\n",
      "    (PP (P in) (NP (Det the) (N park)))))\n",
      "(S\n",
      "  (NP (Det the) (N dog))\n",
      "  (VP\n",
      "    (V saw)\n",
      "    (NP (Det a) (N man))\n",
      "    (PP (P in) (NP (Det the) (N park)))))\n"
     ]
    }
   ],
   "source": [
    "grammar_user = nltk.data.load('file:mygrammar.cfg')\n",
    "sent = 'The dog saw a man in the park'.lower().split()\n",
    "sent2 = 'The dog saw a man'.lower().split()\n",
    "rd_parser = nltk.RecursiveDescentParser(grammar_user, trace=1) # use trace for more step info\n",
    "for x in rd_parser.parse(sent):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Parsing with context free grammar:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shift-reduce parsing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing 'the dog saw a man in the park'\n",
      "    [ * the dog saw a man in the park]\n",
      "  S [ 'the' * dog saw a man in the park]\n",
      "  R [ Det * dog saw a man in the park]\n",
      "  S [ Det 'dog' * saw a man in the park]\n",
      "  R [ Det N * saw a man in the park]\n",
      "  R [ NP * saw a man in the park]\n",
      "  S [ NP 'saw' * a man in the park]\n",
      "  R [ NP V * a man in the park]\n",
      "  S [ NP V 'a' * man in the park]\n",
      "  R [ NP V Det * man in the park]\n",
      "  S [ NP V Det 'man' * in the park]\n",
      "  R [ NP V Det N * in the park]\n",
      "  R [ NP V NP * in the park]\n",
      "  R [ NP VP * in the park]\n",
      "  R [ S * in the park]\n",
      "  S [ S 'in' * the park]\n",
      "  R [ S P * the park]\n",
      "  S [ S P 'the' * park]\n",
      "  R [ S P Det * park]\n",
      "  S [ S P Det 'park' * ]\n",
      "  R [ S P Det N * ]\n",
      "  R [ S P NP * ]\n",
      "  R [ S PP * ]\n"
     ]
    }
   ],
   "source": [
    "sr_parser = nltk.ShiftReduceParser(grammar_user, trace=2)\n",
    "for x in sr_parser.parse(sent):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The left-corner parser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|.  the  .  dog  .  saw  .   a   .  man  .|\n",
      "Leaf Init Rule:\n",
      "|[-------]       .       .       .       .| [0:1] 'the'\n",
      "|.       [-------]       .       .       .| [1:2] 'dog'\n",
      "|.       .       [-------]       .       .| [2:3] 'saw'\n",
      "|.       .       .       [-------]       .| [3:4] 'a'\n",
      "|.       .       .       .       [-------]| [4:5] 'man'\n",
      "Filtered Bottom Up Predict Combine Rule:\n",
      "|[-------]       .       .       .       .| [0:1] Det -> 'the' *\n",
      "Filtered Bottom Up Predict Combine Rule:\n",
      "|[------->       .       .       .       .| [0:1] NP -> Det * N\n",
      "|[------->       .       .       .       .| [0:1] NP -> Det * N PP\n",
      "Filtered Bottom Up Predict Combine Rule:\n",
      "|.       [-------]       .       .       .| [1:2] N  -> 'dog' *\n",
      "Filtered Single Edge Fundamental Rule:\n",
      "|[---------------]       .       .       .| [0:2] NP -> Det N *\n",
      "Filtered Bottom Up Predict Combine Rule:\n",
      "|[--------------->       .       .       .| [0:2] S  -> NP * VP\n",
      "Filtered Bottom Up Predict Combine Rule:\n",
      "|.       .       [-------]       .       .| [2:3] V  -> 'saw' *\n",
      "Filtered Bottom Up Predict Combine Rule:\n",
      "|.       .       [------->       .       .| [2:3] VP -> V * NP\n",
      "|.       .       [------->       .       .| [2:3] VP -> V * NP PP\n",
      "Filtered Bottom Up Predict Combine Rule:\n",
      "|.       .       .       [-------]       .| [3:4] Det -> 'a' *\n",
      "Filtered Bottom Up Predict Combine Rule:\n",
      "|.       .       .       [------->       .| [3:4] NP -> Det * N\n",
      "|.       .       .       [------->       .| [3:4] NP -> Det * N PP\n",
      "Filtered Bottom Up Predict Combine Rule:\n",
      "|.       .       .       .       [-------]| [4:5] N  -> 'man' *\n",
      "Filtered Single Edge Fundamental Rule:\n",
      "|.       .       .       [---------------]| [3:5] NP -> Det N *\n",
      "Filtered Single Edge Fundamental Rule:\n",
      "|.       .       [-----------------------]| [2:5] VP -> V NP *\n",
      "Filtered Single Edge Fundamental Rule:\n",
      "|[=======================================]| [0:5] S  -> NP VP *\n",
      "(S (NP (Det the) (N dog)) (VP (V saw) (NP (Det a) (N man))))\n"
     ]
    }
   ],
   "source": [
    "lc_parser = nltk.LeftCornerChartParser(grammar_user, trace=2)\n",
    "for x in lc_parser.parse(sent2):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Dependencies and dependency grammar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependency grammar with 7 productions\n",
      "  'shot' -> 'I'\n",
      "  'shot' -> 'elephant'\n",
      "  'shot' -> 'in'\n",
      "  'elephant' -> 'an'\n",
      "  'elephant' -> 'in'\n",
      "  'in' -> 'pajamas'\n",
      "  'pajamas' -> 'my'\n"
     ]
    }
   ],
   "source": [
    "groucho_dep_grammar = nltk.DependencyGrammar.fromstring(\"\"\"\n",
    "'shot' -> 'I' | 'elephant' | 'in'\n",
    "'elephant' -> 'an' | 'in'\n",
    "'in' -> 'pajamas'\n",
    "'pajamas' -> 'my'\n",
    "\"\"\")\n",
    "print(groucho_dep_grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Projective dependency parser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(shot I (elephant an (in (pajamas my))))\n",
      "(shot I (elephant an) (in (pajamas my)))\n"
     ]
    }
   ],
   "source": [
    "pdp = nltk.ProjectiveDependencyParser(groucho_dep_grammar)\n",
    "trees = pdp.parse(sent)\n",
    "for x in trees:\n",
    "    #print(x.draw())\n",
    "    print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
